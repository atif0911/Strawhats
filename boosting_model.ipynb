{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to create a model\n",
    "def create_model(input_shape=(128, 128, 3), num_classes=19):\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        MaxPooling2D(2, 2),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(2, 2),\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(2, 2),\n",
    "        Conv2D(256, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(2, 2),\n",
    "        Dropout(0.5),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the data generator (original dataset)\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10752 images belonging to 19 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data = datagen.flow_from_directory(\n",
    "    '/Users/aranyabasu/crop_diseases(BORO_DATA)/train',\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2764 images belonging to 19 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = datagen.flow_from_directory(\n",
    "    '/Users/aranyabasu/crop_diseases(BORO_DATA)/valid',\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to generate bootstrap samples (bags)\n",
    "def create_bagged_generator(generator, n_samples):\n",
    "    # Get all data from the generator\n",
    "    images, labels = next(generator)  # Load the first batch\n",
    "    for i in range(len(generator) - 1):  # Load the rest of the batches\n",
    "        img_batch, lbl_batch = next(generator)\n",
    "        images = np.vstack((images, img_batch))\n",
    "        labels = np.vstack((labels, lbl_batch))\n",
    "\n",
    "    # Randomly sample indices with replacement\n",
    "    sampled_indices = np.random.choice(np.arange(len(images)), size=n_samples, replace=True)\n",
    "    bagged_images = images[sampled_indices]\n",
    "    bagged_labels = labels[sampled_indices]\n",
    "\n",
    "    return ImageDataGenerator().flow(bagged_images, bagged_labels, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train multiple models (bagging with repetition)\n",
    "n_estimators = 5\n",
    "models = []\n",
    "model_dir = 'saved_models'\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "n_samples = train_data.n  # Same size as the original training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 1/5\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-07 00:28:20.408337: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "336/336 [==============================] - 114s 337ms/step - loss: 3.4812 - accuracy: 0.1364 - val_loss: 2.0246 - val_accuracy: 0.3878\n",
      "Epoch 2/10\n",
      "336/336 [==============================] - 116s 346ms/step - loss: 1.8868 - accuracy: 0.4012 - val_loss: 1.2517 - val_accuracy: 0.5944\n",
      "Epoch 3/10\n",
      "336/336 [==============================] - 120s 356ms/step - loss: 1.3797 - accuracy: 0.5460 - val_loss: 1.0534 - val_accuracy: 0.6335\n",
      "Epoch 4/10\n",
      "336/336 [==============================] - 118s 353ms/step - loss: 1.1461 - accuracy: 0.6160 - val_loss: 0.9438 - val_accuracy: 0.6747\n",
      "Epoch 5/10\n",
      "336/336 [==============================] - 117s 350ms/step - loss: 0.9988 - accuracy: 0.6562 - val_loss: 0.8601 - val_accuracy: 0.7044\n",
      "Epoch 6/10\n",
      "336/336 [==============================] - 117s 350ms/step - loss: 0.8774 - accuracy: 0.6837 - val_loss: 0.8517 - val_accuracy: 0.7127\n",
      "Epoch 7/10\n",
      "336/336 [==============================] - 118s 352ms/step - loss: 0.7971 - accuracy: 0.7168 - val_loss: 0.8016 - val_accuracy: 0.7088\n",
      "Epoch 8/10\n",
      "336/336 [==============================] - 118s 351ms/step - loss: 0.7388 - accuracy: 0.7360 - val_loss: 0.7516 - val_accuracy: 0.7113\n",
      "Epoch 9/10\n",
      "336/336 [==============================] - 118s 351ms/step - loss: 0.6571 - accuracy: 0.7641 - val_loss: 0.7725 - val_accuracy: 0.7268\n",
      "Epoch 10/10\n",
      "336/336 [==============================] - 118s 352ms/step - loss: 0.5913 - accuracy: 0.7791 - val_loss: 0.7090 - val_accuracy: 0.7420\n",
      "Training model 2/5\n",
      "Epoch 1/10\n",
      "336/336 [==============================] - 116s 344ms/step - loss: 3.3015 - accuracy: 0.1731 - val_loss: 1.8181 - val_accuracy: 0.4533\n",
      "Epoch 2/10\n",
      "336/336 [==============================] - 119s 355ms/step - loss: 1.8162 - accuracy: 0.4180 - val_loss: 1.2665 - val_accuracy: 0.5868\n",
      "Epoch 3/10\n",
      "336/336 [==============================] - 120s 357ms/step - loss: 1.3431 - accuracy: 0.5664 - val_loss: 1.0288 - val_accuracy: 0.6820\n",
      "Epoch 4/10\n",
      "336/336 [==============================] - 118s 351ms/step - loss: 1.0802 - accuracy: 0.6355 - val_loss: 0.9507 - val_accuracy: 0.6921\n",
      "Epoch 5/10\n",
      "336/336 [==============================] - 118s 350ms/step - loss: 0.9071 - accuracy: 0.6765 - val_loss: 0.9065 - val_accuracy: 0.6889\n",
      "Epoch 6/10\n",
      "336/336 [==============================] - 118s 352ms/step - loss: 0.8096 - accuracy: 0.7111 - val_loss: 0.7593 - val_accuracy: 0.7240\n",
      "Epoch 7/10\n",
      "336/336 [==============================] - 118s 352ms/step - loss: 0.7378 - accuracy: 0.7310 - val_loss: 0.8221 - val_accuracy: 0.7352\n",
      "Epoch 8/10\n",
      "336/336 [==============================] - 118s 352ms/step - loss: 0.6659 - accuracy: 0.7572 - val_loss: 0.7144 - val_accuracy: 0.7435\n",
      "Epoch 9/10\n",
      "336/336 [==============================] - 118s 352ms/step - loss: 0.5977 - accuracy: 0.7745 - val_loss: 0.7218 - val_accuracy: 0.7435\n",
      "Epoch 10/10\n",
      "336/336 [==============================] - 118s 353ms/step - loss: 0.5433 - accuracy: 0.7976 - val_loss: 0.7567 - val_accuracy: 0.7384\n",
      "Training model 3/5\n",
      "Epoch 1/10\n",
      "336/336 [==============================] - 116s 343ms/step - loss: 3.8376 - accuracy: 0.1319 - val_loss: 2.0515 - val_accuracy: 0.3770\n",
      "Epoch 2/10\n",
      "336/336 [==============================] - 117s 348ms/step - loss: 2.0173 - accuracy: 0.3605 - val_loss: 1.4189 - val_accuracy: 0.5109\n",
      "Epoch 3/10\n",
      "336/336 [==============================] - 117s 349ms/step - loss: 1.4535 - accuracy: 0.5273 - val_loss: 1.0739 - val_accuracy: 0.6520\n",
      "Epoch 4/10\n",
      "336/336 [==============================] - 118s 350ms/step - loss: 1.1701 - accuracy: 0.6060 - val_loss: 0.9429 - val_accuracy: 0.6842\n",
      "Epoch 5/10\n",
      "336/336 [==============================] - 118s 350ms/step - loss: 1.0058 - accuracy: 0.6572 - val_loss: 0.8679 - val_accuracy: 0.6990\n",
      "Epoch 6/10\n",
      "336/336 [==============================] - 118s 351ms/step - loss: 0.8643 - accuracy: 0.6971 - val_loss: 0.8496 - val_accuracy: 0.7048\n",
      "Epoch 7/10\n",
      "336/336 [==============================] - 118s 351ms/step - loss: 0.7831 - accuracy: 0.7200 - val_loss: 0.7837 - val_accuracy: 0.7276\n",
      "Epoch 8/10\n",
      "336/336 [==============================] - 118s 351ms/step - loss: 0.7119 - accuracy: 0.7425 - val_loss: 0.7549 - val_accuracy: 0.7265\n",
      "Epoch 9/10\n",
      "336/336 [==============================] - 117s 350ms/step - loss: 0.6600 - accuracy: 0.7623 - val_loss: 0.7413 - val_accuracy: 0.7326\n",
      "Epoch 10/10\n",
      "336/336 [==============================] - 118s 350ms/step - loss: 0.5950 - accuracy: 0.7815 - val_loss: 0.7732 - val_accuracy: 0.7341\n",
      "Training model 4/5\n",
      "Epoch 1/10\n",
      "336/336 [==============================] - 115s 343ms/step - loss: 3.4007 - accuracy: 0.1674 - val_loss: 1.8351 - val_accuracy: 0.4085\n",
      "Epoch 2/10\n",
      "336/336 [==============================] - 116s 347ms/step - loss: 1.8151 - accuracy: 0.4312 - val_loss: 1.2652 - val_accuracy: 0.5995\n",
      "Epoch 3/10\n",
      "336/336 [==============================] - 117s 348ms/step - loss: 1.3625 - accuracy: 0.5658 - val_loss: 1.0488 - val_accuracy: 0.6643\n",
      "Epoch 4/10\n",
      "336/336 [==============================] - 118s 352ms/step - loss: 1.1076 - accuracy: 0.6355 - val_loss: 0.9491 - val_accuracy: 0.6802\n",
      "Epoch 5/10\n",
      "336/336 [==============================] - 119s 356ms/step - loss: 0.9773 - accuracy: 0.6682 - val_loss: 0.8671 - val_accuracy: 0.7113\n",
      "Epoch 6/10\n",
      "336/336 [==============================] - 117s 349ms/step - loss: 0.8470 - accuracy: 0.7072 - val_loss: 0.8254 - val_accuracy: 0.7156\n",
      "Epoch 7/10\n",
      "336/336 [==============================] - 117s 350ms/step - loss: 0.7507 - accuracy: 0.7376 - val_loss: 0.7741 - val_accuracy: 0.7200\n",
      "Epoch 8/10\n",
      "336/336 [==============================] - 118s 350ms/step - loss: 0.6919 - accuracy: 0.7526 - val_loss: 0.7780 - val_accuracy: 0.7167\n",
      "Epoch 9/10\n",
      "336/336 [==============================] - 117s 349ms/step - loss: 0.6186 - accuracy: 0.7769 - val_loss: 0.6757 - val_accuracy: 0.7464\n",
      "Epoch 10/10\n",
      "336/336 [==============================] - 119s 354ms/step - loss: 0.5659 - accuracy: 0.7941 - val_loss: 0.7300 - val_accuracy: 0.7341\n",
      "Training model 5/5\n",
      "Epoch 1/10\n",
      "336/336 [==============================] - 115s 343ms/step - loss: 3.1755 - accuracy: 0.1868 - val_loss: 1.6587 - val_accuracy: 0.4942\n",
      "Epoch 2/10\n",
      "336/336 [==============================] - 117s 350ms/step - loss: 1.6667 - accuracy: 0.4637 - val_loss: 1.1476 - val_accuracy: 0.6328\n",
      "Epoch 3/10\n",
      "336/336 [==============================] - 118s 352ms/step - loss: 1.2359 - accuracy: 0.5893 - val_loss: 0.9922 - val_accuracy: 0.6744\n",
      "Epoch 4/10\n",
      "336/336 [==============================] - 119s 355ms/step - loss: 1.0270 - accuracy: 0.6543 - val_loss: 0.8910 - val_accuracy: 0.6816\n",
      "Epoch 5/10\n",
      "336/336 [==============================] - 117s 350ms/step - loss: 0.8965 - accuracy: 0.6948 - val_loss: 0.8887 - val_accuracy: 0.6827\n",
      "Epoch 6/10\n",
      "336/336 [==============================] - 119s 355ms/step - loss: 0.7714 - accuracy: 0.7325 - val_loss: 0.7708 - val_accuracy: 0.7254\n",
      "Epoch 7/10\n",
      "336/336 [==============================] - 122s 363ms/step - loss: 0.6963 - accuracy: 0.7520 - val_loss: 0.7619 - val_accuracy: 0.7250\n",
      "Epoch 8/10\n",
      "336/336 [==============================] - 124s 371ms/step - loss: 0.6315 - accuracy: 0.7697 - val_loss: 0.7261 - val_accuracy: 0.7326\n",
      "Epoch 9/10\n",
      "336/336 [==============================] - 120s 357ms/step - loss: 0.5837 - accuracy: 0.7889 - val_loss: 0.6974 - val_accuracy: 0.7478\n",
      "Epoch 10/10\n",
      "336/336 [==============================] - 118s 352ms/step - loss: 0.5255 - accuracy: 0.8096 - val_loss: 0.8296 - val_accuracy: 0.7131\n"
     ]
    }
   ],
   "source": [
    "n_samples = train_data.n  # Same size as the original training set\n",
    "\n",
    "for i in range(n_estimators):\n",
    "    print(f\"Training model {i + 1}/{n_estimators}\")\n",
    "    \n",
    "    # Create a bagged generator\n",
    "    bagged_train_generator = create_bagged_generator(train_data, n_samples)\n",
    "\n",
    "    # Create and train model\n",
    "    model = create_model()\n",
    "    model.fit(\n",
    "        bagged_train_generator,\n",
    "        steps_per_epoch=len(bagged_train_generator),\n",
    "        epochs=10,\n",
    "        validation_data=validation_generator,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Save the model after training\n",
    "    model_path = os.path.join(model_dir, f'model_{i+1}.h5')\n",
    "    model_path = os.path.join(model_dir, f'model_{i+1}.keras')\n",
    "    model.save(model_path)\n",
    "    models.append(model_path)  # Save the model file paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 49s 571ms/step\n",
      "87/87 [==============================] - 49s 573ms/step\n",
      "87/87 [==============================] - 50s 575ms/step\n",
      "87/87 [==============================] - 50s 574ms/step\n",
      "87/87 [==============================] - 50s 576ms/step\n"
     ]
    }
   ],
   "source": [
    "# Average predictions across all models\n",
    "def predict_with_bagging(model_paths, data_generator):\n",
    "    predictions = []\n",
    "    \n",
    "    for model_path in model_paths:\n",
    "        model = tf.keras.models.load_model(model_path)\n",
    "        predictions.append(model.predict(data_generator))\n",
    "        \n",
    "    avg_predictions = np.mean(predictions, axis=0)  # Averaging predictions\n",
    "    return np.argmax(avg_predictions, axis=1)\n",
    "\n",
    "# Evaluate on validation data\n",
    "y_true = validation_generator.classes\n",
    "y_pred = predict_with_bagging(models, validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7666\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "accuracy = np.mean(y_true == y_pred)\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Trained_model_V1.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
